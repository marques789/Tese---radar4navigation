%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction} \label{ch:introduction}

%This chapter describes the motivations for this dissertation, followed by its objectives. The contributions done during this dissertation are also presented, along with a succinct description of the documents structure.

%The \ac{VANET} that was used present in his architecture different entities: an \ac{LMA} which is responsible for managing the \ac{VANET}, and also to store information about the overall network status; and the \ac{RSU}s and \ac{OBU}s are also real systems that are called NetRiders - single board computers containing \ac{WAVE}, \ac{WiFi}, \ac{GPS}, and cellular interfaces. This \ac{VANET} is capable of \ac{MH} where it sends the traffic through the different technologies available resulting in a better load balancing, this load balancing mechanism feature is integrated at the \ac{LMA} which is responsible to optimize the traffic division having in mind the different technologies and throughput available for each \ac{PoA}. This \ac{VANET} is also capable of performing \ac{NC} to provide loss reduction, where the encoding is done at the \ac{RSU}s level, where the packets will be encoded through the wireless communications between the \ac{RSU}s and the \ac{OBU}s. 



\section{Context}
The use of autonomous mobile robots has been rapidly expanding over the last few years. Whether its in industry, our homes or in an office like environment, they provide endless applications. A few examples are the use in healthcare, military, agriculture, cleaning, construction and space.
By definition a robot is a device able to perform human activities \cite{robo}.  By programming it, it can fulfill a wide variety of tasks that require the link between perception and  action. A mobile autonomous robot in the other hand is a system that has total mobility in its environment that has limited human interaction and has the ability of perceiving what is around it. In terms of perception robots usually rely on \ac{LiDAR} technology which has some limitations in accurately perceiving what is around them. This is usually the case when the mobile robot is exposed directly to sunlight, smoke, or when trying to detect objects of low height. However \ac{radar} technology has constantly  been  upgraded and is not affected by the previous conditions. Due to recent advancements in terms of hardware and software, new high bandwidth low power radars are now available for the use in perception capabilities for the robot.   
Specifically the \ac{FMCW} \ac{radar} has been constantly improving in terms of being an obstacle detector and  can be used to address the past mentioned problems by being a supportive sensor in the robotic navigation module.
%Automation of mobile robots has been a major subject of interest for a long time.



%This lead to the development of various algorithms to optimize the behavior of robotic platforms when doing navigation tasks. In terms of perception robots usually rely on \ac{LiDAR} technology which has some limitations in accurately perceiving what is around them. However the \ac{FMCW} \ac{radar} can be used to combat this problems by being a supportive sensor in the robotic navigation module.

\section{Objectives}
For this dissertation there are multiple objectives to take in mind. First, a study of how \ac{LiDAR} and the \ac{FMCW} \ac{radar} technology must be conducted in order to understand where they are used and how they work as well as their limitations. After that we must uncover how we can create a suitable robotic platform using \ac{ROS}  and state of the art algorithms to resolve the navigation problems. Moving forward, we want to choose  specific devices and describe what characteristics they have in order to create a suitable navigation platform for our work. After the implementation of the various software and hardware components we want to determine how the \ac{FMCW} \ac{radar} fairs in comparison to the \ac{LiDAR} when used as an obstacle detector for indoor navigation capabilities. Finnaly, we will try to explore how we can use the relative radial velocity retrieved from the \ac{radar} to produce a software application that tries to manipulate the perception of the robot in order to accommodate more safe path trajectories taking into account incoming obstacles. 







%The main focus of this project is to evaluate the performance of the \ac{FMCW} radar technology for the use in robot autonomous indoor navigation.
%For this work there are multiple objectives to take in consideration. First the we must discover in which contexts the \ac{FMCW} \ac{radar} and the \ac{LiDAR} are used and how they work. After the examination we must convert the radar data into the \ac{ROS} platform and process it accordingly in order to create suitable information for the robot to perceive its environment.
 %Once that is completed we can feed it to our navigation system and study how well the robot performs in indoor navigation tasks




%The main focus of this project is to evaluate the performance of the \ac{FMCW} radar technology for the use in robot autonomous indoor navigation. To do this we must first convert the radar data into the \ac{ROS} platform and process it accordingly in order to create suitable information for the robot to perceive its environment. Once that is completed we can feed it to our navigation system and study how well the robot performs in indoor navigation tasks. The focus will be in comparing the performance of this sensors with the more commonly used and more expensive \ac{LiDAR} technology sensors. Since the \ac{FMCW} \ac{radar} retrieves radial velocity information from its targets we can manipulate the information of the costmaps of the navigation module to induce the robot to take safer pathing.

\section{Contributions}
The main contributions of this dissertation are:
\begin{itemize}
    \item Study of the operating principle of the \ac{FMCW} \ac{radar} and the 2D-\ac{LiDAR} as well as demonstrating which works are being done using this type of sensors and what limitations each one has.
    \item Give light to the \ac{ROS} framework and how it can be used to create a suitable navigation platform using state of the art navigation algorithms.
    \item Constructing a navigation platform using turtlebot2, an \ac{FMCW} \ac{radar}, a 2D- \ac{LiDAR} and a processing unit suitable for conducting navigation tasks.
    \item Perform various experiments that evaluate the performance of the previous sensors for obstacle avoidance capabilities.
    \item Create a software module that takes into account the relative radial velocity given by the \ac{radar} and use it to manipulate the obstacle cost of cells around the direction of incoming obstacles.
\end{itemize}




\section{Document Structure}
The dissertation is arranged as follows:

In Chapter 2 a comparative study is done between the \ac{LiDAR} technology and the \ac{FMCW} \ac{radar}. It will give a brief overview of what work is being done using this sensors and what operating principle they rely on as well as describe their limitations. We will also explore the use of ultrasonic sensors and cameras.

Chapter 3 will provide a brief overview of some basic concepts regarding this dissertation's work regarding \ac{ROS} framework, navigation concepts and finally the description of the \ac{ROS} navigation stack.

Chapter 4 we will discuss what hardware and software will be used in this work and how they are interconnected to create a suitable platform for indoor navigation using the previous highlighted sensors.

In Chapter 5 we show the results of various experiments that try to compare the use of \ac{LiDAR} and the \ac{FMCW} \ac{radar} as obstacle detectors.

In Chapter 6 we will discuss how we can use the relative radial velocity of targets given by the \ac{FMCW} \ac{radar} to manipulate the costmaps of the navigation module in order to avoid incoming obstacles.

Finally in Chapter 7 we will make a summary of the work done in this dissertation and what conclusions we found along the way. We will also discuss what future work can be done using this type of sensors for indoor autonomous navigation.



